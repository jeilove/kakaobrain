{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple mixture density network on a regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-22T09:38:49.663978Z",
     "start_time": "2018-02-22T09:38:48.577133Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from [demo_util.ipynb]\n",
      "Packages loaded\n"
     ]
    }
   ],
   "source": [
    "import nbloader\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from demo_util import nzr\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "print (\"Packages loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Generate complex data for tesing mixture density network \n",
    "\"\"\"\n",
    "def get_data4mdn(_xmin=-5.,_xmax=5.,_bias=0,_nsample=1e3):\n",
    "    XMIN,XMAX = _xmin,_xmax\n",
    "    NSAMPLE   = _nsample\n",
    "    _x1 = np.float32(np.random.uniform(XMIN,XMAX,((int)(NSAMPLE/2),1)))\n",
    "    _r1 = np.array([np.random.normal(scale=np.abs(i)) for i in _x1])\n",
    "    _y1 = np.float32((_x1**2)+_r1*1.0) \n",
    "    _z1 = np.float32((_x1**2)-_bias+_r1*1.0) \n",
    "    _x2 = np.float32(np.random.uniform(XMIN,XMAX,((int)(NSAMPLE/2),1)))\n",
    "    _r2 = np.array([np.random.normal(scale=np.abs(i)) for i in _x2])\n",
    "    _y2 = np.float32(-(_x2**2)+_r2*1.0)\n",
    "    _z2 = np.float32(-(_x2**2)+_bias+_r2*1.0)\n",
    "    _xdata = np.concatenate((_x1,_x2),axis=0)\n",
    "    _ydata = np.concatenate((_y1,_y2),axis=0)\n",
    "    _zdata = np.concatenate((_z1,_z2),axis=0)\n",
    "    return _xdata,_ydata,_zdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define MDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class basic_mdn(object):\n",
    "    def __init__(self,_name='',_xdim=1,_ydim=1,_hdims=[64,64],_kmix=2\n",
    "                 ,_actv=tf.nn.relu,_bn=slim.batch_norm\n",
    "                 ,_sigmax=2):\n",
    "        self.name = _name\n",
    "        self.xdim = _xdim\n",
    "        self.ydim = _ydim\n",
    "        self.hdims = _hdims\n",
    "        self.kmix = _kmix\n",
    "        self.actv = _actv \n",
    "        self.bn   = _bn\n",
    "        self.sigmax = _sigmax\n",
    "        \"\"\" Build model \"\"\"\n",
    "        self.build_model()\n",
    "        \"\"\" Build graph \"\"\"\n",
    "        self.build_graph()\n",
    "        \n",
    "        \"\"\" Print \"\"\"\n",
    "        print (\"[%s] instantiated\" %(self.name))\n",
    "        print (\" xdim:[%d],ydim:[%d]\"%(self.xdim,self.ydim))\n",
    "        print (\"Trainable Variables\")\n",
    "        for i in range(len(self.t_vars)):\n",
    "            w_name  = self.t_vars[i].name\n",
    "            w_shape = self.t_vars[i].get_shape().as_list()\n",
    "            print (\" [%02d] Name:[%s] Shape:[%s]\" % (i,w_name,w_shape))\n",
    "        print (\"Global Variables\")\n",
    "        for i in range(len(self.g_vars)):\n",
    "            w_name  = self.g_vars[i].name\n",
    "            w_shape = self.g_vars[i].get_shape().as_list()\n",
    "            print (\" [%02d] Name:[%s] Shape:[%s]\" % (i,w_name,w_shape))\n",
    "        \n",
    "    \"\"\"\n",
    "        Build model\n",
    "    \"\"\"\n",
    "    def build_model(self):\n",
    "        # Placeholders\n",
    "        self.x = tf.placeholder(dtype=tf.float32,shape=[None,self.xdim]) # Input placeholder\n",
    "        self.y = tf.placeholder(dtype=tf.float32,shape=[None,self.ydim]) # Output placeholder\n",
    "        self.kp = tf.placeholder(dtype=tf.float32,shape=[]) # Keep probability \n",
    "        self.lr = tf.placeholder(dtype=tf.float32,shape=[]) # Learning rate\n",
    "        self.wd = tf.placeholder(dtype=tf.float32,shape=[]) # Weight decay rate\n",
    "        self.is_training = tf.placeholder(dtype=tf.bool,shape=[]) # Is training flag\n",
    "        # Initailizers\n",
    "        self.fully_init  = tf.random_normal_initializer(stddev=0.02)\n",
    "        self.bias_init   = tf.constant_initializer(0.)\n",
    "        self.bn_init     = {'beta': tf.constant_initializer(0.),\n",
    "                           'gamma': tf.random_normal_initializer(1., 0.02)}\n",
    "        self.bn_params   = {'is_training':self.is_training,'decay':0.9,'epsilon':1e-5,\n",
    "                           'param_initializers':self.bn_init,'updates_collections': None}\n",
    "        \"\"\" Build graph \"\"\" \n",
    "        with tf.variable_scope('W',reuse=False) as scope:\n",
    "            with slim.arg_scope([slim.fully_connected],activation_fn=self.actv,\n",
    "                                weights_initializer=self.fully_init,biases_initializer=self.bias_init,\n",
    "                                normalizer_fn=self.bn,normalizer_params=self.bn_params,\n",
    "                                weights_regularizer=slim.l2_regularizer(self.wd)):\n",
    "                _net = self.x # Here comes the input\n",
    "                for h_idx in range(len(self.hdims)): # Loop over hidden layers\n",
    "                    _hdim = self.hdims[h_idx]\n",
    "                    _net = slim.fully_connected(_net,_hdim,scope='lin'+str(h_idx))\n",
    "                    _net = slim.dropout(_net,keep_prob=self.kp,is_training=True,scope='dr'+str(h_idx))  \n",
    "                # Class allocation probability \n",
    "                _pi_logits = slim.fully_connected(_net,self.kmix,scope='pi_logits')\n",
    "                _pi = tf.nn.softmax(_pi_logits,dim=1)\n",
    "                # means (data x dim x mixture)\n",
    "                _mu = slim.linear(_net,self.kmix*self.ydim,scope='mu_flatten')\n",
    "                _mu = tf.reshape(_mu,shape=[-1,self.ydim,self.kmix])\n",
    "                # varainces (data x dim x mixture)\n",
    "                _sigma_logits = slim.fully_connected(_net,self.kmix*self.ydim,scope='sigma_logits')\n",
    "                _sigma = self.sigmax*tf.nn.sigmoid(_sigma_logits)\n",
    "                _sigma = tf.reshape(_sigma,shape=[-1,self.ydim,self.kmix])\n",
    "                self.pi = _pi\n",
    "                self.mu = _mu\n",
    "                self.sigma = _sigma\n",
    "        \"\"\" Get trainable and global variables \"\"\"\n",
    "        _t_vars = tf.trainable_variables()\n",
    "        self.t_vars = [var for var in _t_vars if 'W/' in var.name]\n",
    "        _g_vars = tf.global_variables()\n",
    "        self.g_vars = [var for var in _g_vars if 'W/' in var.name]\n",
    "        \n",
    "    \"\"\"\n",
    "        Build Graph\n",
    "    \"\"\"\n",
    "    def build_graph(self):\n",
    "        \"\"\" Likelihood of a gaussian mixture model \"\"\"\n",
    "        y = self.y\n",
    "        pi = self.pi\n",
    "        mu = self.mu\n",
    "        sigma = self.sigma\n",
    "        yrepeat = tf.tile(y[:,:,tf.newaxis],[1,1,self.kmix]) # (N x D x K)\n",
    "        self.quadratics = -0.5*tf.reduce_sum(((yrepeat-mu)/sigma)**2,axis=1) # (N x K)\n",
    "        self.logdet = -0.5*tf.reduce_sum(tf.log(sigma),axis=1) # (N x K)\n",
    "        self.logconstant = - 0.5*self.ydim*tf.log(2*np.pi) # (1)\n",
    "        self.logpi = tf.log(pi) # (N x K)\n",
    "        self.exponents = self.quadratics + self.logdet + self.logconstant + self.logpi\n",
    "        self.logprobs = tf.reduce_logsumexp(self.exponents,axis=1) # (N)\n",
    "        self.gmm_prob = tf.exp(self.logprobs) # (N)\n",
    "        self.gmm_nll  = -tf.reduce_mean(self.logprobs) # (1)\n",
    "        \n",
    "        \"\"\" Loss and optimizer \"\"\"\n",
    "        self.loss = self.gmm_nll + sum(tf.losses.get_regularization_losses())\n",
    "        self.optm = tf.train.AdamOptimizer(learning_rate=self.lr\n",
    "            , beta1=0.9, beta2=0.999, epsilon=0.01).minimize(self.loss)\n",
    "    \n",
    "    def train(self,_sess,_x,_y,max_iter=1000,batch_size=128,print_period=100,plot_period=100,\n",
    "              lr=1e-4,kp=1.0,wd=.0,is_training=True):\n",
    "        from sklearn.utils import shuffle # For batch learning\n",
    "        num_batches = max(_x.shape[0] // batch_size, 1)\n",
    "        batch_size = _x.shape[0] // num_batches\n",
    "        for i in range(max_iter+1):\n",
    "            _x,_y = shuffle(_x,_y)\n",
    "            for j in range(num_batches):\n",
    "                start = j * batch_size\n",
    "                end = (j + 1) * batch_size\n",
    "                feeds = {self.x:_x[start:end,:],self.y:_y[start:end,:]\n",
    "                         ,self.kp:kp,self.lr:lr,self.wd:wd,self.is_training:is_training}\n",
    "                _sess.run(self.optm,feeds)\n",
    "            feeds = {self.x:_x,self.y:_y,self.kp:kp,self.lr:lr,self.wd:wd,\n",
    "                     self.is_training:is_training}\n",
    "            # Plot current result\n",
    "            if (i%plot_period)==0:\n",
    "                nSample = 1\n",
    "                ytest = self.sampler(_sess=_sess,_x=_x,n_samples=nSample)\n",
    "                plt.figure(figsize=(5,3))\n",
    "                plt.plot(_x,_y[:,0],'ro',alpha=0.3)\n",
    "                plt.plot(_x,_y[:,1],'bo',alpha=0.3)\n",
    "                for i in range(nSample):\n",
    "                    plt.plot(_x,ytest[:,0,i],'rx')\n",
    "                    plt.plot(_x,ytest[:,1,i],'bx')\n",
    "                plt.title(\"[%d/%d]\"%(i,max_iter))\n",
    "                plt.show()\n",
    "            # Print current result\n",
    "            if (i%print_period)==0:\n",
    "                loss = _sess.run(self.loss,feeds)\n",
    "                print(\"[%d/%d] loss : %.3e\"%(i,max_iter,loss))\n",
    "        \n",
    "    \"\"\"\n",
    "        Sampler \n",
    "    \"\"\"\n",
    "    def sampler(self,_sess,_x,n_samples=10):\n",
    "        pi, mu, sigma = _sess.run([self.pi, self.mu, self.sigma],\n",
    "                                  feed_dict={self.x:_x,self.kp:1.0,self.is_training:False})\n",
    "        n_points = _x.shape[0]\n",
    "        _y_sampled = np.zeros([n_points,self.ydim,n_samples])\n",
    "        for i in range(n_points):\n",
    "            for j in range(n_samples):\n",
    "                k = np.random.choice(self.kmix,p=pi[i,:])\n",
    "                _y_sampled[i,:,j] = mu[i,:,k] + np.random.randn(1,self.ydim)*sigma[i,:,k]\n",
    "        return _y_sampled\n",
    "        \n",
    "print (\"Class ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate training data for MDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Get Data \"\"\"\n",
    "    xdata,_ydata,_zdata = get_data4mdn(_xmin=-5.,_xmax=5.,_bias=20,_nsample=1e3)\n",
    "    ydata = np.concatenate((_ydata,_zdata),axis=1)\n",
    "    \"\"\" Print \"\"\"\n",
    "    print 'xdata.shape: ',xdata.shape\n",
    "    print 'ydata.shape: ',ydata.shape\n",
    "    \"\"\" Plot \"\"\"\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.plot(xdata,ydata[:,0],'ro',alpha=0.3)\n",
    "    plt.plot(xdata,ydata[:,1],'bo',alpha=0.3)\n",
    "    plt.title('Training data')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate MDN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tf.reset_default_graph()\n",
    "    M = basic_mdn(_name='MDN',_xdim=1,_ydim=2,_hdims=[64,64],\n",
    "                  _kmix=10,_actv=tf.nn.tanh,_bn=slim.batch_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    M.train(_sess=sess,_x=xdata,_y=ydata,\n",
    "            max_iter=1000,batch_size=128,print_period=100,plot_period=100,\n",
    "            lr=1e-4,kp=1.0,wd=.0,is_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ytest = M.sampler(_sess=sess,_x=xdata,n_samples=3)\n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.plot(xdata,ydata[:,0],'ro',alpha=0.3)\n",
    "    plt.plot(xdata,ydata[:,1],'bo',alpha=0.3)\n",
    "    for i in range(3):\n",
    "        plt.plot(xdata,ytest[:,0,i],'rx')\n",
    "        plt.plot(xdata,ytest[:,1,i],'bx')\n",
    "    plt.title('Training data')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
